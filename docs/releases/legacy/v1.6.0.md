# Fury Distribution v1.6.0

Welcome to the **Fury Distribution v1.6.0**. In this new version, we had addressed the update of multiples
packages that belong to the distribution. All of them have been pushed to the latest stable release of each.
It includes testing (as tech preview) against Kubernetes `v1.21.0`.

The team has been working to make the release upgrade as simple as possible, so read carefully the upgrade path of each
core module listed below along with the upgrade path of the distribution.

## Changelog

The most important changes are listed below:

- [networking](https://github.com/sighupio/fury-kubernetes-networking) 📦 core module: v1.5.0 -> [**v1.6.0**](https://github.com/sighupio/fury-kubernetes-networking/releases/tag/v1.6.0)
  - Kubernetes `1.21` Tech preview.
  - Update [Calico] from version `3.17.1` to `3.19.1`.
- [monitoring](https://github.com/sighupio/fury-kubernetes-monitoring) 📦 core module: v1.11.0 -> [**v1.12.0**](https://github.com/sighupio/fury-kubernetes-monitoring/releases/tag/v1.12.0)
  - Kubernetes `1.21` Tech preview.
  - Update [Prometheus Operator] from version `0.44.1` to `0.48.1`.
  - Update [Prometheus] from version `2.22.2` to `2.27.1`.
  - Update [Grafana] from version `7.3.6` to `7.5.7`.
  - Update [metrics-server] from version `0.4.1` to `0.5.0`.
  - Update [Alertmanager] from version `0.21.0` to `0.22.2`.
  - Update [thanos] from version `0.12.2` to `0.20.2`.
    - Fixing thanos modules, missing namespace on components
  - Update [kube-state-metrics] from version `1.9.7` to `2.0.0`.
    - Update all Alerts and Grafana Dashboards
    - Modify the alerts that track expiration of cluster certificates to fire within 30/7 days of expiration instead
    of 7/1 days. (kubeadm-k8s-rules, prometheus-k8s-rules)
  - Update [kube-proxy-metrics]
  - Update [node-exporter] from version `1.0.1` to `1.1.2`.
  - Update [goldpinger] from version `3.0.0` to `3.2.0`.
- [logging](https://github.com/sighupio/fury-kubernetes-logging) 📦 core module: v1.7.0 -> [**v1.8.0**](https://github.com/sighupio/fury-kubernetes-logging/releases/tag/v1.8.0)
  - Kubernetes `1.21` Tech preview.
  - Update [Cerebro] from version `0.9.3` to `0.9.4`.
  - Update [fluentd] from version `1.11.5` to `1.12.3`.
  - Update [fluent-bit] from version `1.6.9` to `1.7.7`.
  - Update [elasticsearch] from version `7.10.1` to `7.13.0`.
  - Update [kibana] from version `7.10.1` to `7.13.0`.
- [ingress](https://github.com/sighupio/fury-kubernetes-ingress) 📦 core module: v1.9.1 -> [**v1.10.0**](https://github.com/sighupio/fury-kubernetes-ingress/releases/tag/v1.10.0)
  - Kubernetes `1.21` Tech preview.
  - Update [forecastle] from version `1.0.61` to `1.0.61`.
  - Update [nginx] ingress controller from version `0.43.0` to `0.46.0`.
  - Update [cert-manager] from version `1.1.0` to `1.3.1`.
- [dr](https://github.com/sighupio/fury-kubernetes-dr) 📦 core module: v1.6.0 -> [**v1.7.0**](https://github.com/sighupio/fury-kubernetes-dr/releases/tag/v1.7.0)
  - Kubernetes `1.21` Tech preview.
  - Update [Velero] from version `1.5.2` to `1.6.0`.
  - Update [Velero] terraform module to use terraform 0.15.4
    - Simplying the terraform interface.
- [OPA](https://github.com/sighupio/fury-kubernetes-opa) 📦 core module: v1.3.0 -> [**v1.4.0**](https://github.com/sighupio/fury-kubernetes-opa/releases/tag/v1.4.0)
  - Kubernetes `1.21` Tech preview.
  - Update [Gatekeeper] from version `v3.2.2` to `v3.4.0`.
    - Add a missing template (unique_service_selector_template) to the template package.
  - Update [Gatekeeper Policy Manager]. Version `v0.4.2`.

## Upgrade path

### Katalog Procedure

To upgrade this distribution from `v1.5.X` to `v1.6.0`, you need to download this new version, vendor the dependencies,
finally applying the `kustomize` project.

```bash
furyctl vendor -H
kustomize build . | kubectl apply -f -
```

> **NOTE**: *The upgrade takes some minutes (depends on the cluster size), and you should expect some downtime during
the upgrade process.*

Then, in order to clean up old resources:

```bash
kubectl delete clusterrolebinding cert-manager-cainjector-leaderelection cert-manager-leaderelection
kubectl delete clusterrole cert-manager-leaderelection
```

### Terraform Procedure

It is important to read the
[Disaster Recovery changelong](https://github.com/sighupio/fury-kubernetes-dr/releases/tag/v1.7.0) to understand how
to move forward the terraform configuration of the Velero components.
Ensure you are running terraform [0.15.4](https://releases.hashicorp.com/terraform/).

## Test it

If you want to test the distribution in a test environment, spin up a
[`kind`](https://github.com/kubernetes-sigs/kind/releases/tag/v0.11.0) cluster, then deploy all rendered manifests.

```bash
$ kind version
kind v0.11.0 go1.16.4 darwin/amd64
$ curl -Ls https://github.com/sighupio/fury-distribution/releases/download/v1.6.0/kind-config-v1.6.0.yml | kind create cluster --config -
Creating cluster "kind" ...
 ✓ Ensuring node image (kindest/node:v1.19.1) 🖼
 ✓ Preparing nodes 📦 📦
 ✓ Writing configuration 📜
 ✓ Starting control-plane 🕹️
 ✓ Installing StorageClass 💾
 ✓ Joining worker nodes 🚜
Set kubectl context to "kind-kind"
You can now use your cluster with:

kubectl cluster-info --context kind-kind

Have a question, bug, or feature request? Let us know! https://kind.sigs.k8s.io/#community 🙂
$ kubectl apply -f https://github.com/sighupio/fury-distribution/releases/download/v1.6.0/fury-distribution-v1.6.0.yml
namespace/cert-manager created
namespace/gatekeeper-system created
namespace/ingress-nginx created
namespace/logging created
namespace/monitoring created
customresourcedefinition.apiextensions.k8s.io/alertmanagers.monitoring.coreos.com created
customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/certificaterequests.cert-manager.io created
customresourcedefinition.apiextensions.k8s.io/certificates.cert-manager.io created
customresourcedefinition.apiextensions.k8s.io/challenges.acme.cert-manager.io created
customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created
<TRUNCATED OUTPUT>
```

> **NOTE**: *Run `kubectl apply` multiple times until you see no errors in the console*

[fluentd]: https://github.com/fluent/fluentd/releases/tag/v1.12.3
[curator]: https://github.com/elastic/curator/releases/tag/v5.8.4
[kibana]: https://github.com/elastic/kibana/releases/tag/v7.13.0
[elasticsearch]: https://github.com/elastic/elasticsearch/releases/tag/v7.13.0
[Cerebro]: https://github.com/lmenezes/cerebro/releases/tag/v0.9.4
[Velero]: https://velero.io/
[cert-manager]: https://github.com/jetstack/cert-manager
[forecastle]: https://github.com/stakater/Forecastle
[nginx]: https://github.com/kubernetes/ingress-nginx
[metrics-server]: https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/metrics-server
[node-exporter]: https://github.com/prometheus/node_exporter
[kube-state-metrics]: https://github.com/kubernetes/kube-state-metrics
[Grafana]: https://grafana.com/
[Alertmanager]: https://github.com/prometheus/alertmanager
[Prometheus]: https://prometheus.io/
[Prometheus Operator]: https://github.com/prometheus-operator/prometheus-operator
[Calico]: https://www.projectcalico.org/
[Gatekeeper]: https://github.com/open-policy-agent/gatekeeper
[Gatekeeper Policy Manager]: https://github.com/sighupio/gatekeeper-policy-manager
[thanos]: https://github.com/thanos-io/thanos
[goldpinger]: https://github.com/bloomberg/goldpinger
[fluent-bit]: https://fluentbit.io/
[kube-proxy-metrics]: https://github.com/sighupio/fury-kubernetes-monitoring/tree/v1.12.0/katalog/kube-proxy-metrics
